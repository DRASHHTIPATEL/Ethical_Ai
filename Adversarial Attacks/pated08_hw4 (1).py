# -*- coding: utf-8 -*-
"""pated08_hw4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13cEJguZUECFsDiy4faOAX1uzg9B_dd9l
"""

#DRASHTI SNEHALKUMAR PATEL
#HW4

#libraries
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import random

#PART 1
def train_model(train_data_path, test_data_path):
    # Load datasets
    train_data = pd.read_csv(train_data_path)
    test_data = pd.read_csv(test_data_path)

    # TF-IDF Vectorizer
    vectorizer = TfidfVectorizer()

    # Transform the text data into TF-IDF features
    X_train = vectorizer.fit_transform(train_data['text'])
    X_test = vectorizer.transform(test_data['text'])

    # Logistic Regression Model
    model = LogisticRegression()

    # Train the model on the training data
    model.fit(X_train, train_data['label'])

    return model, vectorizer, X_test, test_data['label']




#PART 2
# Function to apply random character-level modifications to a word
def character_modify(word):
    modification_type = random.choice(['swap', 'substitute', 'delete'])

    if modification_type == 'swap' and len(word) > 1:
        # Swapping
        i = random.randint(0, len(word) - 2)
        word = list(word)
        word[i], word[i + 1] = word[i + 1], word[i]
        word = ''.join(word)

    elif modification_type == 'substitute':
        substitutions = {'a': '@', 'e': '3', 'i': '1', 'o': '0', 's': '$'}
        word = list(word)
        for i in range(len(word)):
            if word[i] in substitutions:
                word[i] = substitutions[word[i]]
        word = ''.join(word)

    elif modification_type == 'delete' and len(word) > 1:
        i = random.randint(0, len(word) - 1)
        word = word[:i] + word[i + 1:]

    return word


#PART 3
# Function to apply untargeted attack on each word in the text
def untargeted_attack(text):
    words = text.split()
    modified_words = []

    for word in words:
      # 40% chance to modify each word
        if random.random() < 0.4:
            modified_word = character_modify(word)  # Apply modification
            modified_words.append(modified_word)
        else:
            modified_words.append(word)  # Leave word unchanged

    # Join the words back into a text
    modified_text = ' '.join(modified_words)
    return modified_text

# Function to apply untargeted attack to the dataset and save the results
def apply_untargeted_attack_to_dataset(input_file, output_file, model, vectorizer):
    data = pd.read_csv(input_file)

    # Apply the untargeted attack to each text
    data['text'] = data['text'].apply(untargeted_attack)

    # Save the modified texts to a new file
    data.to_csv(output_file, index=False)

# Function to evaluate the model on the modified text 5 times and get the average score
def evaluate_model_on_modified_texts(input_file, model, vectorizer, X_test, true_labels, num_runs=5):
    total_accuracy = 0

    for i in range(num_runs):
        data = pd.read_csv(input_file)
        data['text'] = data['text'].apply(untargeted_attack)
        X_modified = vectorizer.transform(data['text'])
        predictions = model.predict(X_modified)

      # accuracy
        accuracy = accuracy_score(true_labels, predictions)
        print(f"Run {i+1} Accuracy: {accuracy}")
        total_accuracy += accuracy
    average_accuracy = total_accuracy / num_runs
    print(f"\nAverage Accuracy over {num_runs} runs: {average_accuracy}")


#DEFINING PATHS
train_data_path = '/content/train_rotten-tomatoes(in).csv'
test_data_path = '/content/test_rotten-tomatoes(in).csv'

#MODEL TRAINING F CALL
model, vectorizer, X_test, true_labels = train_model(train_data_path, test_data_path)


output_file = '/content/untargeted-attack_rotten-tomatoes.csv'
apply_untargeted_attack_to_dataset(test_data_path, output_file, model, vectorizer)

# Evaluating
evaluate_model_on_modified_texts(output_file, model, vectorizer, X_test, true_labels, num_runs=5)

#PART 4
import random
import pandas as pd
from sklearn.metrics import accuracy_score

# greedy selection function
def greedy_select(text, model, vectorizer, original_label):
    original_probability = model.predict_proba(vectorizer.transform([text]))[0][original_label]
    word_importance = []

    words = text.split()
    #randomness addition
    random.shuffle(words)

    for i, word in enumerate(words):
        text_minus_word = ' '.join(words[:i] + words[i+1:])
        new_probability = model.predict_proba(vectorizer.transform([text_minus_word]))[0][original_label]
        probability_drop = original_probability - new_probability
        word_importance.append((i, word, probability_drop))

   # word sorting from importance
    word_importance.sort(key=lambda x: x[2], reverse=True)
    return word_importance


# Function to apply targeted attack
def targeted_attack(text, model, vectorizer, original_label):
    word_importance = greedy_select(text, model, vectorizer, original_label)
    modified_words = text.split()

    for i, word, _ in word_importance:
        # Apply character-level modification
        modified_words[i] = character_modify(modified_words[i])
        # Checkingcorrect classification
        modified_text = ' '.join(modified_words)
        modified_prob = model.predict_proba(vectorizer.transform([modified_text]))[0][original_label]

        if modified_prob < 0.5:
            print(f"Attack successful: {modified_text}")
            break

    return ' '.join(modified_words)


# Function to apply targeted attack to the dataset and saving it
def apply_targeted_attack_to_dataset(input_file, output_file, model, vectorizer):
    data = pd.read_csv(input_file)

    # Apply the targeted attack to each text
    data['text'] = data.apply(lambda row: targeted_attack(row['text'], model, vectorizer, row['label']), axis=1)
    data.to_csv(output_file, index=False)


# Function to evaluate the model
def evaluate_model_on_modified_texts(input_file, model, vectorizer, true_labels, num_runs=5):
    total_accuracy = 0

    for i in range(num_runs):

        data = pd.read_csv(input_file)
        X_modified = vectorizer.transform(data['text'])

        # predictins
        predictions = model.predict(X_modified)
        accuracy = accuracy_score(true_labels, predictions)
        #print(f"Run {i+1} Accuracy: {accuracy}")

        total_accuracy += accuracy

    # Calculate and print the average accuracy
    average_accuracy = total_accuracy / num_runs
    print("\nAverage Accuracy over 5 runs: {:.4f}".format(average_accuracy))

input_file = '/content/test_rotten-tomatoes(in).csv'
output_file = '/content/targeted-attack_rotten-tomatoes.csv'

# Apply targeted attack func call
apply_targeted_attack_to_dataset(input_file, output_file, model, vectorizer)

# Evaluation
evaluate_model_on_modified_texts(output_file, model, vectorizer, true_labels, num_runs=5)